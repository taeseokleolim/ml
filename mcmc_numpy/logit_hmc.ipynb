{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Work in Progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def leapfrog(q, p, grad, step_size, num_steps):\n",
    "    q_new = q\n",
    "    p_new = p - 0.5 * step_size * grad(q)\n",
    "    for _ in range(num_steps):\n",
    "        q_new += step_size * p_new\n",
    "        if _ != num_steps - 1:\n",
    "            p_new -= step_size * grad(q_new)\n",
    "    p_new -= 0.5 * step_size * grad(q_new)\n",
    "    return q_new, p_new\n",
    "\n",
    "def hmc(grad, initial_position, step_size=0.01, num_steps=10, num_samples=1000):\n",
    "    q = initial_position\n",
    "    samples = [q]\n",
    "    for _ in range(num_samples):\n",
    "        p = np.random.normal(size=q.shape)\n",
    "        q_new, p_new = leapfrog(q, p, grad, step_size, num_steps)\n",
    "        if np.random.rand() < np.exp(-np.sum(grad(q_new)) + np.sum(grad(q)) + 0.5 * (np.dot(p, p) - np.dot(p_new, p_new))):\n",
    "            q = q_new\n",
    "        samples.append(q)\n",
    "    return np.array(samples)\n",
    "\n",
    "# Define the gradient of the negative log likelihood\n",
    "def grad_nll(params, data):\n",
    "    x = data['x']\n",
    "    y = data['y']\n",
    "    beta = params\n",
    "    z = np.dot(x, beta)\n",
    "    prob = 1 / (1 + np.exp(-z))\n",
    "    grad = np.dot(x.T, y - prob)\n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "grad_nll() missing 1 required positional argument: 'data'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 60\u001b[0m\n\u001b[1;32m     58\u001b[0m data \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m'\u001b[39m: X, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m: y}\n\u001b[1;32m     59\u001b[0m initial_position \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m---> 60\u001b[0m samples \u001b[38;5;241m=\u001b[39m hmc(nll, grad_nll, data, initial_position)\n",
      "Cell \u001b[0;32mIn[14], line 49\u001b[0m, in \u001b[0;36mhmc\u001b[0;34m(nll, grad_nll, data, initial_position, step_size, num_steps, num_samples)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_samples):\n\u001b[1;32m     48\u001b[0m     p \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mnormal(size\u001b[38;5;241m=\u001b[39mq\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m---> 49\u001b[0m     q_new, p_new \u001b[38;5;241m=\u001b[39m leapfrog(q, p, grad_nll, step_size, num_steps)\n\u001b[1;32m     50\u001b[0m     current_hamiltonian \u001b[38;5;241m=\u001b[39m hamiltonian(q, p, grad_nll)\n\u001b[1;32m     51\u001b[0m     proposed_hamiltonian \u001b[38;5;241m=\u001b[39m hamiltonian(q_new, p_new, grad_nll)\n",
      "Cell \u001b[0;32mIn[14], line 31\u001b[0m, in \u001b[0;36mleapfrog\u001b[0;34m(q, p, grad, step_size, num_steps)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mleapfrog\u001b[39m(q, p, grad, step_size, num_steps):\n\u001b[1;32m     30\u001b[0m     q_new \u001b[38;5;241m=\u001b[39m q\n\u001b[0;32m---> 31\u001b[0m     p_new \u001b[38;5;241m=\u001b[39m p \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m0.5\u001b[39m \u001b[38;5;241m*\u001b[39m step_size \u001b[38;5;241m*\u001b[39m grad(q)\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_steps):\n\u001b[1;32m     33\u001b[0m         q_new \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m step_size \u001b[38;5;241m*\u001b[39m p_new\n",
      "\u001b[0;31mTypeError\u001b[0m: grad_nll() missing 1 required positional argument: 'data'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00037971, -0.03046507],\n",
       "       [ 0.00037971, -0.03046507],\n",
       "       [ 0.00037971, -0.03046507],\n",
       "       ...,\n",
       "       [ 0.00037971, -0.03046507],\n",
       "       [ 0.00037971, -0.03046507],\n",
       "       [ 0.00037971, -0.03046507]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "manatee",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
